{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((650, 4, 15),\n",
       " (650, 4),\n",
       " array([[[ 1.13400000e+02,  0.00000000e+00,  3.00000000e-01,\n",
       "           0.00000000e+00, -9.44089020e-01, -3.29690645e-01,\n",
       "           1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  1.00000000e+01,  3.52800000e+02,\n",
       "           3.63955000e+02,  1.15311000e+02,  4.07000000e+01],\n",
       "         [ 1.24200000e+02,  0.00000000e+00,  3.00000000e-01,\n",
       "           0.00000000e+00, -9.63630453e-01, -2.67238376e-01,\n",
       "           1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  1.00000000e+01,  3.52800000e+02,\n",
       "           3.63955000e+02,  1.15311000e+02,  4.07000000e+01],\n",
       "         [ 1.29600000e+02,  0.00000000e+00,  3.00000000e-01,\n",
       "           6.65100000e+01, -9.79045472e-01, -2.03641751e-01,\n",
       "           1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  1.00000000e+01,  3.52800000e+02,\n",
       "           3.63955000e+02,  1.15311000e+02,  4.07000000e+01],\n",
       "         [ 1.42200000e+02,  0.00000000e+00,  3.00000000e-01,\n",
       "           0.00000000e+00, -9.90268069e-01, -1.39173101e-01,\n",
       "           1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           0.00000000e+00,  1.00000000e+01,  3.52800000e+02,\n",
       "           3.63955000e+02,  1.15311000e+02,  4.07000000e+01]]]),\n",
       " array([[156.6, 162. , 163.8, 165.6]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 定义处理单个文件的函数\n",
    "def process_file(file_path, window_size=4):\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # 获取所有特征，删除Date列\n",
    "    features = data.drop(columns=[\"Date\"]).values\n",
    "    targets = data[\"CGM (mg / dl)\"].values\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data) - 2 * window_size):\n",
    "        X.append(features[i : i + window_size])  # 保持时间窗口内的特征维度\n",
    "        y.append(\n",
    "            targets[i + window_size : i + 2 * window_size]\n",
    "        )  # 目标是下四个时间点的血糖值\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "# 测试处理单个文件\n",
    "file_path = \"dataset/T1DM/1001_0_20210730.csv\"\n",
    "X, y = process_file(file_path)\n",
    "\n",
    "X.shape, y.shape, X[:1], y[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All X shape: (127170, 4, 15)\n",
      "All y shape: (127170, 4)\n",
      "Sample X: [[[ 1.13400000e+02  0.00000000e+00  3.00000000e-01  0.00000000e+00\n",
      "   -9.44089020e-01 -3.29690645e-01  1.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  1.00000000e+01  3.52800000e+02\n",
      "    3.63955000e+02  1.15311000e+02  4.07000000e+01]\n",
      "  [ 1.24200000e+02  0.00000000e+00  3.00000000e-01  0.00000000e+00\n",
      "   -9.63630453e-01 -2.67238376e-01  1.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  1.00000000e+01  3.52800000e+02\n",
      "    3.63955000e+02  1.15311000e+02  4.07000000e+01]\n",
      "  [ 1.29600000e+02  0.00000000e+00  3.00000000e-01  6.65100000e+01\n",
      "   -9.79045472e-01 -2.03641751e-01  1.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  1.00000000e+01  3.52800000e+02\n",
      "    3.63955000e+02  1.15311000e+02  4.07000000e+01]\n",
      "  [ 1.42200000e+02  0.00000000e+00  3.00000000e-01  0.00000000e+00\n",
      "   -9.90268069e-01 -1.39173101e-01  1.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  1.00000000e+01  3.52800000e+02\n",
      "    3.63955000e+02  1.15311000e+02  4.07000000e+01]]]\n",
      "Sample y: [[156.6 162.  163.8 165.6]]\n",
      "Data proportion from dataset/T1DM/: 12.24%\n",
      "Data proportion from dataset/T2DM: 87.76%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# 定义处理单个文件的函数\n",
    "def process_file(file_path, window_size=4):\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # 获取所有特征，删除Date列\n",
    "    features = data.drop(columns=[\"Date\"]).values\n",
    "    targets = data[\"CGM (mg / dl)\"].values\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data) - 2 * window_size):\n",
    "        X.append(features[i : i + window_size])  # 保持时间窗口内的特征维度\n",
    "        y.append(\n",
    "            targets[i + window_size : i + 2 * window_size]\n",
    "        )  # 目标是下四个时间点的血糖值\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "# 文件夹路径\n",
    "directory_paths = [\"dataset/T1DM\", \"dataset/T2DM\"]\n",
    "\n",
    "# 处理所有CSV文件并组合结果\n",
    "all_X = []\n",
    "all_y = []\n",
    "\n",
    "# 用于存储每个文件夹中的数据量\n",
    "folder_data_counts = {}\n",
    "\n",
    "for directory_path in directory_paths:\n",
    "    folder_X = []\n",
    "    folder_y = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            try:\n",
    "                X, y = process_file(file_path)\n",
    "                folder_X.append(X)\n",
    "                folder_y.append(y)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {filename} in {directory_path}: {e}\")\n",
    "\n",
    "    # 记录每个文件夹中的数据量\n",
    "    folder_X = np.concatenate(folder_X, axis=0)\n",
    "    folder_y = np.concatenate(folder_y, axis=0)\n",
    "    folder_data_counts[directory_path] = len(folder_X)\n",
    "\n",
    "    all_X.append(folder_X)\n",
    "    all_y.append(folder_y)\n",
    "\n",
    "all_X = np.concatenate(all_X, axis=0)\n",
    "all_y = np.concatenate(all_y, axis=0)\n",
    "\n",
    "# 显示结果数据的形状\n",
    "print(\"All X shape:\", all_X.shape)\n",
    "print(\"All y shape:\", all_y.shape)\n",
    "\n",
    "# 检查前几个样本\n",
    "print(\"Sample X:\", all_X[:1])\n",
    "print(\"Sample y:\", all_y[:1])\n",
    "\n",
    "# 计算并显示各文件夹数据的比重\n",
    "total_data_count = len(all_X)\n",
    "for folder, count in folder_data_counts.items():\n",
    "    proportion = count / total_data_count\n",
    "    print(f\"Data proportion from {folder}: {proportion:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All X shape: (83558, 4, 15)\n",
      "All y shape: (83558, 4)\n",
      "Sample X: [[[ 1.51200000e+02  0.00000000e+00  9.00000000e-01  0.00000000e+00\n",
      "    8.92978943e-01 -4.50098441e-01  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  2.00000000e+00  2.60000000e+01  1.81800000e+02\n",
      "    7.54710000e+02  6.94050000e+01  1.96000000e+01]\n",
      "  [ 1.42200000e+02  0.00000000e+00  6.00000000e-01  0.00000000e+00\n",
      "    8.61629160e-01 -5.07538363e-01  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  2.00000000e+00  2.60000000e+01  1.81800000e+02\n",
      "    7.54710000e+02  6.94050000e+01  1.96000000e+01]\n",
      "  [ 1.31400000e+02  0.00000000e+00  6.00000000e-01  0.00000000e+00\n",
      "    8.26589749e-01 -5.62804928e-01  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  2.00000000e+00  2.60000000e+01  1.81800000e+02\n",
      "    7.54710000e+02  6.94050000e+01  1.96000000e+01]\n",
      "  [ 1.13400000e+02  0.00000000e+00  6.00000000e-01  0.00000000e+00\n",
      "    7.88010754e-01 -6.15661475e-01  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  2.00000000e+00  2.60000000e+01  1.81800000e+02\n",
      "    7.54710000e+02  6.94050000e+01  1.96000000e+01]]]\n",
      "Sample y: [[97.2 82.8 70.2 63. ]]\n",
      "Data proportion from dataset/T1DM: 46.57%\n",
      "Data proportion from dataset/T2DM: 53.43%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# 定义处理单个文件的函数\n",
    "def process_file(file_path, window_size=4):\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # 获取所有特征，删除Date列\n",
    "    features = data.drop(columns=[\"Date\"]).values\n",
    "    targets = data[\"CGM (mg / dl)\"].values\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data) - 2 * window_size):\n",
    "        X.append(features[i : i + window_size])  # 保持时间窗口内的特征维度\n",
    "        y.append(\n",
    "            targets[i + window_size : i + 2 * window_size]\n",
    "        )  # 目标是下四个时间点的血糖值\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "# 文件夹路径\n",
    "directory_paths = [\"dataset/T1DM\", \"dataset/T2DM\"]\n",
    "\n",
    "# 处理所有CSV文件并组合结果\n",
    "all_X = []\n",
    "all_y = []\n",
    "\n",
    "# 用于存储每个文件夹中的数据量\n",
    "folder_data_counts = {}\n",
    "\n",
    "for directory_path in directory_paths:\n",
    "    folder_X = []\n",
    "    folder_y = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            try:\n",
    "                X, y = process_file(file_path)\n",
    "                folder_X.append(X)\n",
    "                folder_y.append(y)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {filename} in {directory_path}: {e}\")\n",
    "\n",
    "    # 合并文件夹内的所有数据\n",
    "    folder_X = np.concatenate(folder_X, axis=0)\n",
    "    folder_y = np.concatenate(folder_y, axis=0)\n",
    "\n",
    "    # 对T1DM数据进行随机上采样2.5倍\n",
    "    if \"T1DM\" in directory_path:\n",
    "        upsample_indices = np.random.choice(\n",
    "            len(folder_X), size=int(len(folder_X) * 2.5), replace=True\n",
    "        )\n",
    "        folder_X = folder_X[upsample_indices]\n",
    "        folder_y = folder_y[upsample_indices]\n",
    "\n",
    "    # 对T2DM数据进行随机下采样40%\n",
    "    if \"T2DM\" in directory_path:\n",
    "        sample_indices = np.random.choice(\n",
    "            len(folder_X), size=int(len(folder_X) * 0.4), replace=False\n",
    "        )\n",
    "        folder_X = folder_X[sample_indices]\n",
    "        folder_y = folder_y[sample_indices]\n",
    "\n",
    "    # 记录每个文件夹中的数据量（采样后）\n",
    "    folder_data_counts[directory_path] = len(folder_X)\n",
    "\n",
    "    all_X.append(folder_X)\n",
    "    all_y.append(folder_y)\n",
    "\n",
    "all_X = np.concatenate(all_X, axis=0)\n",
    "all_y = np.concatenate(all_y, axis=0)\n",
    "\n",
    "# 显示结果数据的形状\n",
    "print(\"All X shape:\", all_X.shape)\n",
    "print(\"All y shape:\", all_y.shape)\n",
    "\n",
    "# 检查前几个样本\n",
    "print(\"Sample X:\", all_X[:1])\n",
    "print(\"Sample y:\", all_y[:1])\n",
    "\n",
    "# 计算并显示各文件夹数据的比重（采样后）\n",
    "total_data_count = len(all_X)\n",
    "for folder, count in folder_data_counts.items():\n",
    "    proportion = count / total_data_count\n",
    "    print(f\"Data proportion from {folder}: {proportion:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
